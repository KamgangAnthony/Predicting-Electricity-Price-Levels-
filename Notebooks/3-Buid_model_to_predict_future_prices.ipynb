{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f66de753",
   "metadata": {},
   "source": [
    "Here we create the model but first we verify if buying batteries for the solar panels would also be profitable. \n",
    "The company has solar panels but no batteries for the moment.\n",
    "For this example, the company wants to buy batteries of 70MWh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119a323-a32e-4767-84b1-d535b50fea23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sell high, buy low using battery storage\n",
    "Exploring the prospect of using battery storage to store some of the energy produced when prices are low to then sell it for a higher price later.\n",
    "\n",
    "To keep things simple, I'm making a few simplifying assumptions:\n",
    "- Any energy stored today needs to be sold by the end of tomorrow (although more energy can be stored at tomorrows price so effectively this rule does nothing)\n",
    "- Ignore costs due to battery cycling. Batteries can undergo a finite number of charge-discharge cycles, after which they need to be replaced, but I'm ignoring any costs due to this (and these costs are likely to be high)\n",
    "- If predicted price for tomorrow is higher than for today, I'm fully filling up the batteries (if the solar arrays aren't producing, just get electricity from the grid).\n",
    "\n",
    "## Excecutive summary\n",
    "- The cost for a 70 MWh battery in 2022 is 11.9 million AUD at a minimum\n",
    "- With perfect information on tomorrows prices, could make 314,000 AUD per year based on data for 2015-2020\n",
    "- The maximum return on investment is then 2.6% yearly, ignoring depreciation of batteries over time\n",
    "- Using an ensemble learning stacked model to predict when to fill up the batteries, the company can reach a precision of 64% of the maximum profits \n",
    "- Possibly could make higher profits by selling during time of day when demand is peaking?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e18912-2069-40cc-a55c-d0dd20ba5fd6",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39dfcef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c3ea861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.12'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94925e03-acee-4a7a-83d6-cf4ac461b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import sem\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "plt.style.use('seaborn-deep')\n",
    "plt.rcParams['figure.figsize'] = (16,9)\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b729b6e-37b2-4170-a985-5b3c1a7e0da8",
   "metadata": {},
   "source": [
    "## Import and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1300fa2d-562a-4b03-b7f8-61773461856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/KamgangAnthony/Predicting-Electricity-Price-Levels-/main/complete_dataset.csv')\n",
    "    column_mapper = {\"RRP\":\"price\", \"demand_pos_RRP\":\"demand_pos_price\", \"RRP_positive\":\"price_positive\", \"demand_neg_RRP\":\"demand_neg_price\", \"RRP_negative\":\"price_negative\", \"frac_at_neg_RRP\":\"frac_neg_price\"}\n",
    "    df.rename(columns = column_mapper, inplace = True)\n",
    "\n",
    "    # Convert datatypes\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df.school_day = df.school_day.map({\"N\": False, \"Y\":True}).astype('bool')\n",
    "    df.holiday = df.holiday.map({\"N\": False, \"Y\":True}).astype('bool')\n",
    "\n",
    "    # Extract year, month and day of week from data\n",
    "    df['year'] = df.date.dt.year\n",
    "    df['month'] = df.date.dt.month\n",
    "    df['dow'] = df.date.dt.day_of_week\n",
    "    df['week'] = df.date.dt.isocalendar().week.astype('int')\n",
    "\n",
    "    # Convert solar exposure from MJ/m^2 to MWh/m^2 (1 MJ = 1/(60*60) MWh)\n",
    "    df.solar_exposure = df.solar_exposure/3600\n",
    "\n",
    "    # Set date as index so can do resampling using pandas\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc9d3b18-29df-4d5a-a1a6-4d8cca0e6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09bbdf1",
   "metadata": {},
   "source": [
    "In this first part, we will predict the maximum profit in theory. It is as if the models predicted with 100% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8667f656-e975-494f-87c5-25b17fc00859",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cost for a 70 MWh battery\n",
    "The cost per unit capacity for lithium ion batteries is something like 120-350 USD/kWh = 170-490 AUD/kWh ([National Renewable Energy Laboratory](https://www.nrel.gov/docs/fy21osti/79236.pdf), estimate for [Tesla](https://www.forbes.com/sites/greatspeculations/2021/12/01/are-battery-cost-improvements-still-a-big-driver-of-teslas-margins/?sh=447fbdcb4ae7), [Wikipedia](https://en.wikipedia.org/wiki/Sodium-ion_battery#Advantages_and_disadvantages_over_other_battery_technologies)), so a 70 MWh battery would cost around 12 - 34 million AUD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f425a7d-0dd2-473c-b2a1-1a50ee569781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost for 70 MWh battery at 170.0 AUD/kWh is 11.90 million AUD\n"
     ]
    }
   ],
   "source": [
    "battery_price_per_kWh = 170\n",
    "battery_price = 70000*battery_price_per_kWh/1e6\n",
    "print(f\"Cost for 70 MWh battery at {battery_price_per_kWh:.1f} AUD/kWh is {battery_price:.2f} million AUD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f1d4cb-26be-41f5-bd68-95b2c4a338b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How well is it possible to do in theory?\n",
    "If we were able to predict the future perfectly, how much money could we make using a 70 MWh battery system? The strategy would be to fill up the batteries whenever today's price is lower than tomorrow's.\n",
    "\n",
    "Calculate the profit that would be made everyday:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "093c4150-5ed0-4238-a6d9-07af9b49124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_tomorrow'] = df.price.shift(-1,'D')\n",
    "df['fill_battery'] = df.price_tomorrow > df.price\n",
    "df['profit'] = (df.price_tomorrow - df.price)*df.fill_battery*70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b681db-0b03-4c05-9e10-830da3f2c98c",
   "metadata": {},
   "source": [
    "Total profit over the entire time period is then roughly \\\\$1.8M, which corresponds to a daily profit of roughly 860 AUD (314,000 AUD yearly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "529b8622-52f8-42a2-b6ba-2fea72bad305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total maximum profit over time period in data: 1.81 million AUD\n",
      "Mean daily profit over time period in data: 861 AUD (314.3k AUD yearly)\n",
      "Maximal yearly ROI for battery: 2.6%\n"
     ]
    }
   ],
   "source": [
    "total_profit = df.profit.sum()/1e6\n",
    "print(f\"Total maximum profit over time period in data: {total_profit:.2f} million AUD\")\n",
    "\n",
    "daily_profit = df.profit.mean()\n",
    "print(f\"Mean daily profit over time period in data: {daily_profit:.0f} AUD ({daily_profit*365/1e3:.1f}k AUD yearly)\")\n",
    "\n",
    "annual_ROI = daily_profit*365/(battery_price*1e6)\n",
    "print(f\"Maximal yearly ROI for battery: {annual_ROI*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee5517-bf5c-453e-a6ea-0a31f89c6650",
   "metadata": {},
   "source": [
    "The **maximum yearly return on investment is thus approximately 2.6%**, which is very low compared to typical returns for stocks and comparable to government bonds, with the caveat that the calculation here isn't taking into account account the depreciation of the batteries (which would further reduce the ROI). It would take the batteries roughly **40 years to pay back for themselves**, and it seems unlikely they would remain functional for that long (at least based on my personal experience with cell phone batteries...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d34309-ace4-45b7-94ee-99c0e1aa5069",
   "metadata": {
    "tags": []
   },
   "source": [
    "## To charge or not to charge - how well can we do in practice?\n",
    "In practice we don't have perfect information about tomorrow's electricity prices, so we are probably not able to reach the theoretical maximum profit for the battery system. Using ***data science*** it may be possible to predict whether or not tomorrow's price is higher than today's and make the decision to fill or not to fill the batteries based on a predictive model. In this section, I'm going to train a simple linear regression model to predict the price of electricity on a given day, provided the following information:\n",
    "- Price of electricity for the past 7 days. We would probably have access to this data by the time we have to decide if we want to charge the batteries for tomorrow (current days prices might not be available in practice, but I'll assume they are for now).\n",
    "- Weather info: min and max temperature, rainfall and solar exposure for the day. Weather forecasts are typically quite accurate for the next day, so we would have access to good approximations of this information.\n",
    "- Historic electricity demand for the given day\n",
    "- What day of the week is the day we are trying to predict, and is it a holiday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7b470-951e-4625-b1bb-fe6f3ce497df",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "Generating the data needed for training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "259682e1-5855-4a96-ad29-16ea11cd8847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_data(df: pd.DataFrame, N_prev = 7, N_folds = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates data that is used to train a model to predict electricity prices on a given day.\n",
    "    The for loop will create new price_x columns with missing values in them corresponding to the number of days we remove from\n",
    "    that column.\n",
    "    df.attrs is used to remember N_prev as a sort of global variable(an attribute to the dataframe)\n",
    "    dropna we then drop the rows with missing values to get rows with the values for the last 7 days\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = ['demand',\n",
    "               'price',\n",
    "               'min_temperature',\n",
    "               'max_temperature',\n",
    "               'solar_exposure',\n",
    "               'rainfall',\n",
    "               'school_day',\n",
    "               'holiday',\n",
    "               'week']\n",
    "    df = df.copy()[columns]\n",
    "    \n",
    "    # Get prices for N_prev days and store them as new columns\n",
    "    for n in range(1,N_prev+1):\n",
    "        df[f'price_{n}'] = df.price.shift(n,'D')\n",
    "    \n",
    "    df.attrs['N_prev'] = N_prev\n",
    "        \n",
    "    # Remove dates where previous prices are not available\n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    # Split data into folds for use in cross validation\n",
    "    date_max = df.index.max()\n",
    "    day = pd.Timedelta(1,'D')\n",
    "    df['fold'] = 0\n",
    "    for i, n in enumerate(range(N_folds,0,-1)):\n",
    "        df.loc[date_max-(i+1)*100*day:date_max-i*100*day, 'fold'] = n\n",
    "    \n",
    "    df.reset_index(inplace = True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def generate_train_test(df: pd.DataFrame, fold: int) -> Tuple[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generates train and test datasets for a given test fold\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    train = df[df.fold < fold]\n",
    "    y_train = train.pop('price')\n",
    "    X_train = train.drop(columns = ['demand','fold'])\n",
    "    \n",
    "    test = df[df.fold == fold]\n",
    "    y_test = test.pop('price')\n",
    "    X_test = test.drop(columns = ['demand', 'fold'])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def get_X_y(df: pd.DataFrame) -> Tuple[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Separates dataframe to features and target.\n",
    "    \"\"\"\n",
    "    \n",
    "    y = df.pop('price')\n",
    "    X = df.drop(columns = ['demand', 'fold'])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472ca20-70a3-4811-88e5-9f576895255c",
   "metadata": {},
   "source": [
    "### Transform data\n",
    "Define a pipeline for transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e4001d4-6af6-4342-97bd-93e9886fbc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df: pd.DataFrame, fold: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transforms the input data to be fit by the predictive model\n",
    "    \"\"\"\n",
    "    df = calc_weekly_median(df)\n",
    "    df = calc_historical_price(df, fold)    \n",
    "    df = calc_historical_demand(df, fold)\n",
    "    \n",
    "    df.set_index('date', inplace = True)\n",
    "\n",
    "    return df\n",
    "    \n",
    "def calc_weekly_median(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates the median price of electricity for the past 7 days for each date in data.\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    for n in range(1,df.attrs['N_prev']+1):\n",
    "        cols.append(f'price_{n}')\n",
    "        \n",
    "    df['median_price'] = df[cols].median(axis = 1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def calc_historical_price(df: pd.DataFrame, fold: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates median historical price by week for each date using only data that is before the validation period \n",
    "    (but not using data from future).\n",
    "    Here we first select the rows that are before the validation period using the fold, then we take the median price of every\n",
    "    week from the rows remaining, which we convert to a new column, reset the index for week to come out. Then we merge\n",
    "    it with the original dataframe to add the historical_median to the original df.\n",
    "    \"\"\"\n",
    "    df = df.merge(df[df.fold < fold].groupby('week').price.median().to_frame('historical_median').reset_index(), on = 'week')\n",
    "    return df\n",
    "\n",
    "def calc_historical_demand(df: pd.DataFrame, fold: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates median historical demand by week for each date in data (but not using data from future).\n",
    "    Same as above except here it is for the demand\n",
    "    \"\"\"\n",
    "    df = df.merge(df[df.fold < fold].groupby('week').demand.median().to_frame('historical_demand').reset_index(), on = 'week')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce507a2-18d8-4fd4-ad8c-e8bd65054205",
   "metadata": {},
   "source": [
    "### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "970cbf0c-bec0-43d4-8dd0-fd479e78c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_lin_reg(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sets up a linear regression model, fits it to data and makes predictions.\n",
    "    \"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    preds = X_test.copy()\n",
    "    preds['predicted_price'] = y_pred\n",
    "    preds['predicted_buy'] = (preds.predicted_price - preds.price_1) > 0 #if tomorrows' predicted price is greater than \n",
    "    #today's price then predicted_buy is true(time to recharge the batteries for sale tomorrow (^-^)\n",
    "\n",
    "    return preds\n",
    "\n",
    "def fit_predict_LGBM(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame, params: dict = {}) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sets up a linear gradient boosting model, fits it to data and makes predictions.\n",
    "    \"\"\"\n",
    "    model = LGBMRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    preds = X_test.copy()\n",
    "    preds['predicted_price'] = y_pred\n",
    "    preds['predicted_buy'] = (preds.predicted_price - preds.price_1) > 0 #if tomorrows' predicted price is greater than \n",
    "    #today's price then predicted_buy is true(time to recharge the batteries for sale tomorrow (^-^)\n",
    "\n",
    "    return preds\n",
    "\n",
    "def fit_predict_GBM(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sets up a gradient boosting model, fits it to data and makes predictions.\n",
    "    \"\"\"\n",
    "    model = GradientBoostingRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    preds = X_test.copy()\n",
    "    preds['predicted_price'] = y_pred\n",
    "    preds['predicted_buy'] = (preds.predicted_price - preds.price_1) > 0 #if tomorrows' predicted price is greater than \n",
    "    #today's price then predicted_buy is true(time to recharge the batteries for sale tomorrow (^-^)\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "def fit_predict_BRM(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sets up a bagging regressor model, fits it to data and makes predictions.\n",
    "    \"\"\"\n",
    "    dt = LGBMRegressor()\n",
    "    model = BaggingRegressor(base_estimator=dt, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    preds = X_test.copy()\n",
    "    preds['predicted_price'] = y_pred\n",
    "    preds['predicted_buy'] = (preds.predicted_price - preds.price_1) > 0 #if tomorrows' predicted price is greater than \n",
    "    #today's price then predicted_buy is true(time to recharge the batteries for sale tomorrow (^-^)\n",
    "\n",
    "    return preds\n",
    "\n",
    "def fit_predict_RFR(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sets up a random forest regressor model, fits it to data and makes predictions.\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    preds = X_test.copy()\n",
    "    preds['predicted_price'] = y_pred\n",
    "    preds['predicted_buy'] = (preds.predicted_price - preds.price_1) > 0 #if tomorrows' predicted price is greater than \n",
    "    #today's price then predicted_buy is true(time to recharge the batteries for sale tomorrow (^-^)\n",
    "\n",
    "    return preds\n",
    "\n",
    "def fit_predict_VR(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sets up a voting regressor model, fits it to data and makes predictions.\n",
    "    \"\"\"\n",
    "    LGBM = LGBMRegressor()\n",
    "    BR = BaggingRegressor(base_estimator=LGBM, n_jobs=-1)\n",
    "    GBR = GradientBoostingRegressor()\n",
    "    classifiers = [('Bagging Regressor', BR), ('Gradient Boosting Regressor', GBR)]\n",
    "    model = VotingRegressor(estimators=classifiers)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    preds = X_test.copy()\n",
    "    preds['predicted_price'] = y_pred\n",
    "    preds['predicted_buy'] = (preds.predicted_price - preds.price_1) > 0 #if tomorrows' predicted price is greater than \n",
    "    #today's price then predicted_buy is true(time to recharge the batteries for sale tomorrow (^-^)\n",
    "\n",
    "    return preds\n",
    "\n",
    "def fit_predict_ELSR(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sets up an ensemble stacked regressor model combining bagging, gradient boosting regressor and \n",
    "    linear regression, fits it to data and makes predictions.\n",
    "    \"\"\"\n",
    "    LGBM = LGBMRegressor()\n",
    "    BR = BaggingRegressor(base_estimator=LGBM, n_jobs=-1)\n",
    "    GBR = GradientBoostingRegressor()\n",
    "    BR.fit(X_train, y_train)\n",
    "    GBR.fit(X_train, y_train)\n",
    "    pred_br = BR.predict(X_train)\n",
    "    pred_gbr = GBR.predict(X_train)\n",
    "    pred_df = pd.DataFrame({'pred_br': pred_br,'pred_gbr': pred_gbr})\n",
    "    pred_df = pred_df.set_index(X_train.index)\n",
    "    X_train_2nd = pd.concat([X_train, pred_df], axis=1)\n",
    "    clf_stack = LinearRegression()\n",
    "    clf_stack.fit(X_train_2nd, y_train)\n",
    "    pred_br = BR.predict(X_test)\n",
    "    pred_gbr = GBR.predict(X_test)\n",
    "    pred_df = pd.DataFrame({'pred_br': pred_br,'pred_gbr': pred_gbr})\n",
    "    pred_df = pred_df.set_index(X_test.index)\n",
    "    X_test_2nd = pd.concat([X_test, pred_df], axis=1)\n",
    "    pred_stack = clf_stack.predict(X_test_2nd)\n",
    "\n",
    "    y_pred = pred_stack\n",
    "    \n",
    "    preds = X_test.copy()\n",
    "    preds['predicted_price'] = y_pred\n",
    "    preds['predicted_buy'] = (preds.predicted_price - preds.price_1) > 0 #if tomorrows' predicted price is greater than \n",
    "    #today's price then predicted_buy is true(time to recharge the batteries for sale tomorrow (^-^)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54dabad-7259-479b-b0fe-0083ca953637",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "771a097e-6b42-4502-be7a-ba3580ea110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_buy_percentage(y_true, y_pred) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the percentage of days where the model was able to corectly predict\n",
    "    if the battery should be filled or not.\n",
    "    \"\"\"\n",
    "    return np.mean(y_true==y_pred)\n",
    "\n",
    "def percentage_of_max_profit(df) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the percentage of the max profit that was obtained.\n",
    "    \"\"\"\n",
    "    return df.profit.sum()/df.max_profit.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1100635c-9821-452b-8d82-d7ca66ba30f3",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c34f8fab-9f32-4adb-bc04-1fd6283d990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_LR(N_folds: int = 5):\n",
    "    \"\"\"\n",
    "    Repeats the data generation, training, and testing of the model for\n",
    "    different folds.\n",
    "    \"\"\"\n",
    "    df = load_data()\n",
    "    data_all_folds = generate_model_data(df)\n",
    "    \n",
    "    result_dict = {}\n",
    "    result_dict['mape'] = []\n",
    "    result_dict['cbp'] = []\n",
    "    result_dict['pomp'] = []\n",
    "    \n",
    "    # Loop over the folds\n",
    "    for fold in range(1, N_folds+1):\n",
    "        data = transform_data(data_all_folds, fold)\n",
    "        X_train, y_train, X_test, y_test = generate_train_test(data, fold)\n",
    "        preds = fit_predict_lin_reg(X_train, y_train, X_test)\n",
    "        \n",
    "        # Calculate data needed for calculating metrics\n",
    "        preds['true_price'] = y_test\n",
    "        preds['true_buy'] = (preds.true_price - preds.price_1) > 0\n",
    "        preds['profit'] = (preds.true_price - preds.price_1)*preds.predicted_buy*70\n",
    "        preds['max_profit'] = (preds.true_price - preds.price_1)*preds.true_buy*70\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mape = mean_absolute_percentage_error(preds.true_price, preds.predicted_price)\n",
    "        cbp = correct_buy_percentage(preds.true_buy, preds.predicted_buy)\n",
    "        pomp = percentage_of_max_profit(preds)\n",
    "        \n",
    "        result_dict['mape'].append(mape)\n",
    "        result_dict['cbp'].append(cbp)\n",
    "        result_dict['pomp'].append(pomp)\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "def cross_validate_LGBM(N_folds: int = 5):\n",
    "    \"\"\"\n",
    "    Repeats the data generation, training, and testing of the model for\n",
    "    different folds.\n",
    "    \"\"\"\n",
    "    df = load_data()\n",
    "    data_all_folds = generate_model_data(df)\n",
    "    \n",
    "    result_dict = {}\n",
    "    result_dict['mape'] = []\n",
    "    result_dict['cbp'] = []\n",
    "    result_dict['pomp'] = []\n",
    "    \n",
    "    # Loop over the folds\n",
    "    for fold in range(1, N_folds+1):\n",
    "        data = transform_data(data_all_folds, fold)\n",
    "        X_train, y_train, X_test, y_test = generate_train_test(data, fold)\n",
    "        preds = fit_predict_LGBM(X_train, y_train, X_test)\n",
    "        \n",
    "        # Calculate data needed for calculating metrics\n",
    "        preds['true_price'] = y_test\n",
    "        preds['true_buy'] = (preds.true_price - preds.price_1) > 0\n",
    "        preds['profit'] = (preds.true_price - preds.price_1)*preds.predicted_buy*70\n",
    "        preds['max_profit'] = (preds.true_price - preds.price_1)*preds.true_buy*70\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mape = mean_absolute_percentage_error(preds.true_price, preds.predicted_price)\n",
    "        cbp = correct_buy_percentage(preds.true_buy, preds.predicted_buy)\n",
    "        pomp = percentage_of_max_profit(preds)\n",
    "        \n",
    "        result_dict['mape'].append(mape)\n",
    "        result_dict['cbp'].append(cbp)\n",
    "        result_dict['pomp'].append(pomp)\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "def cross_validate_GBM(N_folds: int = 5):\n",
    "    \"\"\"\n",
    "    Repeats the data generation, training, and testing of the model for\n",
    "    different folds.\n",
    "    \"\"\"\n",
    "    df = load_data()\n",
    "    data_all_folds = generate_model_data(df)\n",
    "    \n",
    "    result_dict = {}\n",
    "    result_dict['mape'] = []\n",
    "    result_dict['cbp'] = []\n",
    "    result_dict['pomp'] = []\n",
    "    \n",
    "    # Loop over the folds\n",
    "    for fold in range(1, N_folds+1):\n",
    "        data = transform_data(data_all_folds, fold)\n",
    "        X_train, y_train, X_test, y_test = generate_train_test(data, fold)\n",
    "        preds = fit_predict_GBM(X_train, y_train, X_test)\n",
    "        \n",
    "        # Calculate data needed for calculating metrics\n",
    "        preds['true_price'] = y_test\n",
    "        preds['true_buy'] = (preds.true_price - preds.price_1) > 0\n",
    "        preds['profit'] = (preds.true_price - preds.price_1)*preds.predicted_buy*70\n",
    "        preds['max_profit'] = (preds.true_price - preds.price_1)*preds.true_buy*70\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mape = mean_absolute_percentage_error(preds.true_price, preds.predicted_price)\n",
    "        cbp = correct_buy_percentage(preds.true_buy, preds.predicted_buy)\n",
    "        pomp = percentage_of_max_profit(preds)\n",
    "        \n",
    "        result_dict['mape'].append(mape)\n",
    "        result_dict['cbp'].append(cbp)\n",
    "        result_dict['pomp'].append(pomp)\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "def cross_validate_BRM(N_folds: int = 5):\n",
    "    \"\"\"\n",
    "    Repeats the data generation, training, and testing of the model for\n",
    "    different folds.\n",
    "    \"\"\"\n",
    "    df = load_data()\n",
    "    data_all_folds = generate_model_data(df)\n",
    "    \n",
    "    result_dict = {}\n",
    "    result_dict['mape'] = []\n",
    "    result_dict['cbp'] = []\n",
    "    result_dict['pomp'] = []\n",
    "    \n",
    "    # Loop over the folds\n",
    "    for fold in range(1, N_folds+1):\n",
    "        data = transform_data(data_all_folds, fold)\n",
    "        X_train, y_train, X_test, y_test = generate_train_test(data, fold)\n",
    "        preds = fit_predict_BRM(X_train, y_train, X_test)\n",
    "        \n",
    "        # Calculate data needed for calculating metrics\n",
    "        preds['true_price'] = y_test\n",
    "        preds['true_buy'] = (preds.true_price - preds.price_1) > 0\n",
    "        preds['profit'] = (preds.true_price - preds.price_1)*preds.predicted_buy*70\n",
    "        preds['max_profit'] = (preds.true_price - preds.price_1)*preds.true_buy*70\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mape = mean_absolute_percentage_error(preds.true_price, preds.predicted_price)\n",
    "        cbp = correct_buy_percentage(preds.true_buy, preds.predicted_buy)\n",
    "        pomp = percentage_of_max_profit(preds)\n",
    "        \n",
    "        result_dict['mape'].append(mape)\n",
    "        result_dict['cbp'].append(cbp)\n",
    "        result_dict['pomp'].append(pomp)\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "def cross_validate_RFR(N_folds: int = 5):\n",
    "    \"\"\"\n",
    "    Repeats the data generation, training, and testing of the model for\n",
    "    different folds.\n",
    "    \"\"\"\n",
    "    df = load_data()\n",
    "    data_all_folds = generate_model_data(df)\n",
    "    \n",
    "    result_dict = {}\n",
    "    result_dict['mape'] = []\n",
    "    result_dict['cbp'] = []\n",
    "    result_dict['pomp'] = []\n",
    "    \n",
    "    # Loop over the folds\n",
    "    for fold in range(1, N_folds+1):\n",
    "        data = transform_data(data_all_folds, fold)\n",
    "        X_train, y_train, X_test, y_test = generate_train_test(data, fold)\n",
    "        preds = fit_predict_RFR(X_train, y_train, X_test)\n",
    "        \n",
    "        # Calculate data needed for calculating metrics\n",
    "        preds['true_price'] = y_test\n",
    "        preds['true_buy'] = (preds.true_price - preds.price_1) > 0\n",
    "        preds['profit'] = (preds.true_price - preds.price_1)*preds.predicted_buy*70\n",
    "        preds['max_profit'] = (preds.true_price - preds.price_1)*preds.true_buy*70\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mape = mean_absolute_percentage_error(preds.true_price, preds.predicted_price)\n",
    "        cbp = correct_buy_percentage(preds.true_buy, preds.predicted_buy)\n",
    "        pomp = percentage_of_max_profit(preds)\n",
    "        \n",
    "        result_dict['mape'].append(mape)\n",
    "        result_dict['cbp'].append(cbp)\n",
    "        result_dict['pomp'].append(pomp)\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "def cross_validate_VR(N_folds: int = 5):\n",
    "    \"\"\"\n",
    "    Repeats the data generation, training, and testing of the model for\n",
    "    different folds.\n",
    "    \"\"\"\n",
    "    df = load_data()\n",
    "    data_all_folds = generate_model_data(df)\n",
    "    \n",
    "    result_dict = {}\n",
    "    result_dict['mape'] = []\n",
    "    result_dict['cbp'] = []\n",
    "    result_dict['pomp'] = []\n",
    "    \n",
    "    # Loop over the folds\n",
    "    for fold in range(1, N_folds+1):\n",
    "        data = transform_data(data_all_folds, fold)\n",
    "        X_train, y_train, X_test, y_test = generate_train_test(data, fold)\n",
    "        preds = fit_predict_VR(X_train, y_train, X_test)\n",
    "        \n",
    "        # Calculate data needed for calculating metrics\n",
    "        preds['true_price'] = y_test\n",
    "        preds['true_buy'] = (preds.true_price - preds.price_1) > 0\n",
    "        preds['profit'] = (preds.true_price - preds.price_1)*preds.predicted_buy*70\n",
    "        preds['max_profit'] = (preds.true_price - preds.price_1)*preds.true_buy*70\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mape = mean_absolute_percentage_error(preds.true_price, preds.predicted_price)\n",
    "        cbp = correct_buy_percentage(preds.true_buy, preds.predicted_buy)\n",
    "        pomp = percentage_of_max_profit(preds)\n",
    "        \n",
    "        result_dict['mape'].append(mape)\n",
    "        result_dict['cbp'].append(cbp)\n",
    "        result_dict['pomp'].append(pomp)\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "def cross_validate_ELSR(N_folds: int = 5):\n",
    "    \"\"\"\n",
    "    Repeats the data generation, training, and testing of the model for\n",
    "    different folds.\n",
    "    \"\"\"\n",
    "    df = load_data()\n",
    "    data_all_folds = generate_model_data(df)\n",
    "    \n",
    "    result_dict = {}\n",
    "    result_dict['mape'] = []\n",
    "    result_dict['cbp'] = []\n",
    "    result_dict['pomp'] = []\n",
    "    \n",
    "    # Loop over the folds\n",
    "    for fold in range(1, N_folds+1):\n",
    "        data = transform_data(data_all_folds, fold)\n",
    "        X_train, y_train, X_test, y_test = generate_train_test(data, fold)\n",
    "        preds = fit_predict_ELSR(X_train, y_train, X_test)\n",
    "        \n",
    "        # Calculate data needed for calculating metrics\n",
    "        preds['true_price'] = y_test\n",
    "        preds['true_buy'] = (preds.true_price - preds.price_1) > 0\n",
    "        preds['profit'] = (preds.true_price - preds.price_1)*preds.predicted_buy*70\n",
    "        preds['max_profit'] = (preds.true_price - preds.price_1)*preds.true_buy*70\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mape = mean_absolute_percentage_error(preds.true_price, preds.predicted_price)\n",
    "        cbp = correct_buy_percentage(preds.true_buy, preds.predicted_buy)\n",
    "        pomp = percentage_of_max_profit(preds)\n",
    "        \n",
    "        result_dict['mape'].append(mape)\n",
    "        result_dict['cbp'].append(cbp)\n",
    "        result_dict['pomp'].append(pomp)\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def show_summary_stats(results_dict: dict):\n",
    "    \"\"\"\n",
    "    Print the the mean and error in mean accross different folds\n",
    "    \"\"\"\n",
    "    for metric, values in results_dict.items():\n",
    "        mean = np.mean(values)\n",
    "        std_err = sem(values)\n",
    "        print(f\"Mean for {metric}: {mean:.3f}+/-{std_err:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4f0cc1d-95a9-4635-85dd-830f689d66af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for mape: 0.394+/-0.078\n",
      "Mean for cbp: 0.621+/-0.013\n",
      "Mean for pomp: 0.412+/-0.026\n"
     ]
    }
   ],
   "source": [
    "show_summary_stats(cross_validate_LGBM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a974dc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for mape: 0.379+/-0.080\n",
      "Mean for cbp: 0.639+/-0.012\n",
      "Mean for pomp: 0.452+/-0.012\n"
     ]
    }
   ],
   "source": [
    "show_summary_stats(cross_validate_GBM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25b63031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for mape: 0.647+/-0.172\n",
      "Mean for cbp: 0.503+/-0.040\n",
      "Mean for pomp: 0.081+/-0.102\n"
     ]
    }
   ],
   "source": [
    "show_summary_stats(cross_validate_LR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49d3518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for mape: 0.392+/-0.094\n",
      "Mean for cbp: 0.635+/-0.011\n",
      "Mean for pomp: 0.424+/-0.040\n"
     ]
    }
   ],
   "source": [
    "show_summary_stats(cross_validate_BRM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2946ed84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for mape: 0.419+/-0.106\n",
      "Mean for cbp: 0.625+/-0.009\n",
      "Mean for pomp: 0.403+/-0.023\n"
     ]
    }
   ],
   "source": [
    "show_summary_stats(cross_validate_RFR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0df9546e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for mape: 0.378+/-0.086\n",
      "Mean for cbp: 0.639+/-0.008\n",
      "Mean for pomp: 0.461+/-0.038\n"
     ]
    }
   ],
   "source": [
    "show_summary_stats(cross_validate_VR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d0aafe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for mape: 0.363+/-0.072\n",
      "Mean for cbp: 0.633+/-0.013\n",
      "Mean for pomp: 0.444+/-0.021\n"
     ]
    }
   ],
   "source": [
    "show_summary_stats(cross_validate_ELSR())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2414376",
   "metadata": {},
   "source": [
    "So here our best model has a MAPE of ~36% which is about 64% accuracy so we will not even get the 2.6% ROI per year. \n",
    "We will get just about 64% of that in reality. \n",
    "Conclusion: It is profitable to invest in the solar panels but not the batteries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
